{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차(금)_CNN실습(공유).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mR70xBiVr9z_MFMaZp-4AerjUo0TA68-",
      "authorship_tag": "ABX9TyNQfPKanEUmnot+EE+NsJ99",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "111763cc377f43ca8e89484f57674bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea85f11fa2d0409b89fce1e6e10d0d92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bfb3a0c9aee240568c94eb008fa760ea",
              "IPY_MODEL_75c9a295441c4b14a7e65de02d6f78fb",
              "IPY_MODEL_d27481c9dca0416ca08cc47cd663c02b"
            ]
          }
        },
        "ea85f11fa2d0409b89fce1e6e10d0d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfb3a0c9aee240568c94eb008fa760ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ed42c48fddf4de6b8b0930b9f30b18b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64d2490a10aa47c7b0d3dcb353904274"
          }
        },
        "75c9a295441c4b14a7e65de02d6f78fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52eb6692e5754c4eb9282cc063dd44dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1610624ba4c34343966b63af90ed9e3a"
          }
        },
        "d27481c9dca0416ca08cc47cd663c02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a29ff938706749c7bb668d3f9f45f216",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 180MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c784488f7ce4816aeb0156b60c33fcf"
          }
        },
        "5ed42c48fddf4de6b8b0930b9f30b18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64d2490a10aa47c7b0d3dcb353904274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52eb6692e5754c4eb9282cc063dd44dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1610624ba4c34343966b63af90ed9e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a29ff938706749c7bb668d3f9f45f216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c784488f7ce4816aeb0156b60c33fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunjeong-chang/2022_AI_Practical_Course/blob/main/3%EC%A3%BC%EC%B0%A8(%EA%B8%88)_CNN%EC%8B%A4%EC%8A%B5(%EA%B3%B5%EC%9C%A0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. 데이터 불러오기\n",
        "https://drive.google.com/file/d/1M8KwdmGm8EWCn_IEWAcctbUJBww-M3cF/view?usp=sharing\n",
        "\n",
        "1. 위 링크에 있는 zip 파일을 '드라이브에 바로가기 추가'하기(안되면 그냥 다운로드 후 내 드라이브에 업로드)\n",
        "2. GPU 설정 후, 드라이브 마운트\n",
        "3. zip 파일 풀기 (약 2분 소요)"
      ],
      "metadata": {
        "id": "TDekbT7bHvKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -uq “압축을 풀 zip 파일의 경로” -d “압축을 풀고자 하는 폴더의 경로”\n",
        "!unzip -uq /content/drive/MyDrive/plant-leaf-dataset.zip -d /content/drive/MyDrive/plant-leaf-dataset"
      ],
      "metadata": {
        "id": "0CrELDhBI3yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAmOFLpdtXV5"
      },
      "source": [
        "### 1. 데이터 분할을 위한 디렉토리 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH7lRtSlpG7c"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "original_dataset_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-dataset' #데이터셋이 위치한 경로 지정  \n",
        "classes_list = os.listdir(original_dataset_dir) #해당 경로 하위에 있는 모든 폴더의 목록을 가져옴(폴더 목록 == 클래스 목록)\n",
        " \n",
        "base_dir = '/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset' #train/val/test로 분할한 데이터를 저장할 폴더 생성\n",
        "os.mkdir(base_dir)\n",
        " \n",
        "train_dir = os.path.join(base_dir, 'train') #train 폴더 생성\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val') #\bvalidation 폴더 생성\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test') #test 폴더 생성\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list: #train/val/test 폴더에 각각 클래스 목록 폴더를 생성    \n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. train/validation/test 데이터 분할 및 클래스 별 데이터 수 확인"
      ],
      "metadata": {
        "id": "eKJ1QY2e28i4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0a0PUSrdnZ",
        "outputId": "ce483767-281b-44f7-c78e-682dda5a65e5"
      },
      "source": [
        "import math\n",
        "for cls in classes_list: #모든 클래스에 대한 작업 반복\n",
        "    path = os.path.join(original_dataset_dir, cls) \n",
        "    fnames = os.listdir(path) #path 위치에 존재하는 모든 이미지 파일의 목록을 fnames에 저장\n",
        "    \n",
        "    #train/validation/test 의 비율을 6:2:2로 (데이터 규모에 따라 조정 가능)\n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "    \n",
        "    #train\n",
        "    train_fnames = fnames[:train_size] #train 데이터에 해당하는 파일의 이름을 train_fnames에 저장\n",
        "    for fname in train_fnames: #train 데이터에 대해 for문의 내용 반복\n",
        "        src = os.path.join(path, fname) #복사할 원본 파일의 경로 지정\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname) #복사한 후 저장할 파일의 경로 지정\n",
        "        shutil.copyfile(src, dst) #src의 경로에 해당하는 파일을 dst의 경로에 지정\n",
        "    \n",
        "    #validation\n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    #test    \n",
        "    test_fnames = fnames[(train_size + validation_size):(test_size + validation_size + train_size)]\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    print(\"class(\",cls,\") Train:\",len(train_fnames), \"Validation:\",len(validation_fnames), \"Test:\",len(test_fnames))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class( Apple___healthy ) Train: 987 Validation: 329 Test: 329\n",
            "class( Grape___healthy ) Train: 253 Validation: 84 Test: 84\n",
            "class( Grape___Black_rot ) Train: 708 Validation: 236 Test: 236\n",
            "class( Peach___Bacterial_spot ) Train: 1378 Validation: 459 Test: 459\n",
            "class( Potato___healthy ) Train: 91 Validation: 30 Test: 30\n",
            "class( Potato___Early_blight ) Train: 600 Validation: 200 Test: 200\n",
            "class( Corn___Common_rust ) Train: 715 Validation: 238 Test: 238\n",
            "class( Strawberry___Leaf_scorch ) Train: 671 Validation: 223 Test: 223\n",
            "class( Apple___Apple_scab ) Train: 378 Validation: 126 Test: 126\n",
            "class( Strawberry___healthy ) Train: 273 Validation: 91 Test: 91\n",
            "class( Peach___healthy ) Train: 216 Validation: 72 Test: 72\n",
            "class( Corn___healthy ) Train: 697 Validation: 232 Test: 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYCY0sqFso7L"
      },
      "source": [
        "### 3. 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucURIVBmsnmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbb2bf6-b2d9-4fd4-8865-de9bf3000d25"
      },
      "source": [
        "import torch\n",
        "import os\n",
        " \n",
        "USE_CUDA = torch.cuda.is_available() #GPU 사용 가능한지 확인하는 메서드(사용할 수 있으면 TRUE, 없으면 FALSE 반환)\n",
        "print(USE_CUDA)\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\") #DEVICE 변수에 TRUE 이면 cuda를 FALSE 이면 cpu를 저장\n",
        "print(DEVICE)\n",
        "\n",
        "BATCH_SIZE = 512 #배치사이즈 지정\n",
        "EPOCH = 5 #에포크 지정\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "data_transforms = { # transforms.Compose()는 이미지 전처리, Augmentation 등 사용, Augmentation이란? 좌우 반전, 밝기 조절, 이미지 확대 등 노이즈를 주어 더 강한 모델을 만들어 주는 기법\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]), # Resize -> 이미지의 크기를 64x64로 조정                    \n",
        "                                 transforms.RandomHorizontalFlip(), #RandomHorizontalFlip -> 이미지를 무작위로 좌우 반전\n",
        "                                 transforms.RandomVerticalFlip(), #RandomVerticalFlip -> 이미지를 무작위로 상하 반전\n",
        "                                 transforms.RandomCrop(52), #RandomCrop -> 이미지의 일부를 랜덤하게 잘라서 52x52 사이즈로 변경\n",
        "                                 transforms.ToTensor(), # ToTensor -> 이미지를 텐서 형태로 변환하고, 모든 값을 0~1 사이로 변경\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), #Normalize ->정규화를 위해선 평균값과 표준편차값이 필요\n",
        "                                                                                                        #            첫번째[]는 R,G,B 채널 값에서 정규화를 적용할 평균값 \n",
        "                                                                                                        #            두번째[]는 R,G,B 채널 값에서 정규화를 적용할 표준편차값 \n",
        "                                                                                                        #            이 값은 이미지넷 데이터의 값이고, 정규화는 Local Minimum에 빠지는 것을 방지\n",
        "    'val': transforms.Compose([transforms.Resize([64,64]), \n",
        "                               #validation data는 Augmentation에 해당하는 부분을 제외하고 동일하게 전처리 \n",
        "                               transforms.RandomCrop(52), \n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 데이터 로더"
      ],
      "metadata": {
        "id": "e0zmtPpS9oAW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STs5oRi2sy12",
        "outputId": "c09a8c49-3fae-41b0-aa9d-854c7e365ef0"
      },
      "source": [
        "from torchvision.datasets import ImageFolder #이미지 데이터는 하나의 클래스가 하나의 폴더에 대응되기 때문에 데이터셋을 불러올 때 ImageFolder를 사용\n",
        "\n",
        "# ImageFolder로 데이터셋 불러오기 -> root : 데이터 불러 올 경로 설정, transform : 앞서 설정한 전처리 방법 지정(불러오기 편하게 딕셔너리 형태로 구성)\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(base_dir, x), transform=data_transforms[x]) for x in ['train', 'val']} \n",
        "\n",
        "# DataLoader로 불러온 이미지 데이터를 주어진 조건에 따라 미니 배치 단위로 분리 -> shuffle=True : 데이터의 순서가 섞여 학습시에 Label 정보의 순서를 기억하는 것을 방지 할 수 있음 필수!\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']} \n",
        "\n",
        "#train/validation의 총 개수를 저장\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "#12개 클래스의 목록을 저장\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple___Apple_scab', 'Apple___healthy', 'Corn___Common_rust', 'Corn___healthy', 'Grape___Black_rot', 'Grape___healthy', 'Peach___Bacterial_spot', 'Peach___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Strawberry___Leaf_scorch', 'Strawberry___healthy']\n",
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 전이학습 모델 불러오기\n",
        "1. 모델만 불러와서 구조 print 해보기\n",
        "2. 분류층 바꾸고 print 해보기"
      ],
      "metadata": {
        "id": "Uy5j3kc79q6x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZEFZgmTs2Vt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "111763cc377f43ca8e89484f57674bc8",
            "ea85f11fa2d0409b89fce1e6e10d0d92",
            "bfb3a0c9aee240568c94eb008fa760ea",
            "75c9a295441c4b14a7e65de02d6f78fb",
            "d27481c9dca0416ca08cc47cd663c02b",
            "5ed42c48fddf4de6b8b0930b9f30b18b",
            "64d2490a10aa47c7b0d3dcb353904274",
            "52eb6692e5754c4eb9282cc063dd44dd",
            "1610624ba4c34343966b63af90ed9e3a",
            "a29ff938706749c7bb668d3f9f45f216",
            "2c784488f7ce4816aeb0156b60c33fcf"
          ]
        },
        "outputId": "69badc79-e470-4b85-c13b-51c43b96ef33"
      },
      "source": [
        "from torchvision import models #pytorch 공식문서에서 확인 한 것처럼, 여기서 여러 모델을 불러올 수 있음\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#resnet18/34/50 \n",
        "model = models.resnet50(pretrained=True) #pretrained=True로 설정하면 pre-trained model의 parameter값을 그대로 가져옴, False로 설정하면 모델의 아키텍처만 가져오고 parameter는 랜덤 설정\n",
        "num_ftrs = model.fc.in_features #모델의 마지막 레이어의 입력 채널의 수를 저장(in_features는 해당 레이어의 입력 채널 수를 의미)   \n",
        "model.fc = nn.Linear(num_ftrs, len(class_names)) #모델의 마지막 레이어를 새로운 레이어로 교체 (입력 채널 수는 기존 레이어와 동일, 출력 채널 수를 우리가 원하는 수로 설정하는 것! 여기서는 클래스 수 12개) \n",
        "\n",
        "'''\n",
        "#vgg16/19\n",
        "model = models.vgg16(pretrained=True)\n",
        "#model.classifier[6].out_features = len(class_names) #마지막 레이어를 교체하는 방법이 약간 다름, print 해서 구조 확인하면서 이해\n",
        "\n",
        "#mobilenet_v2\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "#model.classifier[1].out_features = len(class_names)\n",
        "\n",
        "#mobilnet_v3_small\n",
        "model = models.mobilenet_v3_small(pretrained=True)\n",
        "#model.classifier[3].out_features = len(class_names)\n",
        "'''\n",
        "\n",
        "model = model.to(DEVICE) #모델 gpu에 태우기\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "111763cc377f43ca8e89484f57674bc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=12, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Layer Freeze"
      ],
      "metadata": {
        "id": "4zzyFflRf13T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wf8IIPgs3vs"
      },
      "source": [
        "cnt = 0 #몇 번째 Layer인지 나타내는 변수 cnt 설정\n",
        "for child in model.children(): #모델의 모든 Layer 정보를 담고 있음 (vgg, mobilenet 계열은 model.features)\n",
        "    cnt += 1 \n",
        "    if cnt < 6: #resnet50기준 10개의 Layer중 1~5개는 Freeze하고, 6~10은 학습 시 parameter를 업데이트 하도록!\n",
        "        #print(child)\n",
        "        for param in child.parameters(): #vgg, mobilenet 계열은 model.features.parameters()\n",
        "            param.requires_grad = False  #False -> NO UPDATE(FREEZE), True -> UPDATE(기본값)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 손실함수, 최적화함수, 스케쥴러 설정\n",
        "- Adam vs SGD\n",
        "- learning rate는 작게!\n",
        "- 미리 학습 코드까지 실행!"
      ],
      "metadata": {
        "id": "onKCFqbZf9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습에 사용하는 Loss 함수를 지정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Optimizer는 Adam, filter와 lambda를 사용하는 이유 : param.requires_grad = True로 설정된 Layer의 parameter만을 업데이트 하기 위해서!\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00001) \n",
        " \n",
        "from torch.optim import lr_scheduler\n",
        "# 에포크에 따라 Learning Rate를 변경하는 역할 (7 에포크마다 0.1씩 곱해 LR을 감소시킴), Why? : 학습 보폭을 정하는 일은 매우 중요한데, 처음엔 크게 -> 학습 진행될 수록 작게 설정하는 것이 좋다고 알려짐, but 아직 연구중\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "LfwDUXcaD_uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 모델 학습 및 저장"
      ],
      "metadata": {
        "id": "t86IqtKnK8Qr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXFjVMs3s5Jv"
      },
      "source": [
        "# 전이학습 모델 학습 및 검증\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    \n",
        "    train_losses , train_accuracy = [],[] #그래프 그리기 위해서 train에 대한 loss,accuracy 저장\n",
        "    val_losses , val_accuracy = [],[] #그래프 그리기 위해서 validation에 대한 loss,accuracy 저장\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())  #정확도가 가장 높은 모델을 저장\n",
        "    best_acc = 0.0 #정확도가 가장 높은 모델의 정확도 저장\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('-------------- epoch {} ----------------'.format(epoch+1)) \n",
        "        since = time.time() #한 에포크 돌 때 소요되는 시간 측정(시작 시각 저장)                                    \n",
        "        for phase in ['train', 'val']: #한 에포크 돌 때 train 한 번, validation 한 번씩 각각 진행\n",
        "            if phase == 'train': \n",
        "                model.train() #train이면 학습 모드\n",
        "            else:\n",
        "                model.eval() #validation이면 평가 모드(평가 때 사용하지 말아야 할 작업들 알아서 꺼줌, dropout이나 batchnorm layer 같은 것들)     \n",
        " \n",
        "            running_loss = 0.0   #모든 데이터의 loss를 합해서 저장\n",
        "            running_corrects = 0 #정확하게 예측한 경우의 수를 저장\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: #모델의 현재 모드(train or validation)에 해당하는 Dataloader에서 데이터를 받는 for문\n",
        "                inputs = inputs.to(DEVICE) #데이터를 gpu에 태움 \n",
        "                labels = labels.to(DEVICE) #데이터의 라벨값을 gpu에 태움\n",
        "                \n",
        "                optimizer.zero_grad() #학습 진행하면 이전 Batch의 Gradient값이 Optimizer에 저장될 것이므로 초기화 해주고 시작해야 함\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'): #set_grad_enabled를 이용하면 train 모드에서만 모델의 Gradient를 업데이트 하도록 설정 할 수 있음\n",
        "                    outputs = model(inputs) #드디어 데이터를 모델에 입력!\n",
        "                    _, preds = torch.max(outputs, 1) #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 preds에 저장\n",
        "                    loss = criterion(outputs, labels) #모델의 예측값과 정답값 사이의 Loss를 계산(criterion 함수는 위에서 미리 설정해 둔 것)\n",
        "    \n",
        "                    if phase == 'train':   \n",
        "                        loss.backward() #계산한 loss값을 이용하여 BackPropagation을 통해 계산한 Gradient값을 parameter에 할당하고,\n",
        "                        optimizer.step() #모델의 parameter 업데이트\n",
        " \n",
        "                running_loss += loss.item() * inputs.size(0) #모든 데이터의 loss를 합해서 저장하기 위해, 하나의 미니 배치에 대한 loss값에 데이터의 수를 곱해서 더함 (inputs.size(0)이 미니 배치의 수) \n",
        "                running_corrects += torch.sum(preds == labels.data) #예측값과 정답값이 같으면 증가!\n",
        "\n",
        "            if phase == 'train':  \n",
        "                scheduler.step() #위에서 미리 설정한 Scheduler 실행\n",
        " \n",
        "            epoch_loss = running_loss/dataset_sizes[phase] #해당 에포크의 loss를 계산하기 위해 running_loss를 데이터셋 사이즈로 나눔\n",
        "            epoch_acc = running_corrects.double()/dataset_sizes[phase] #정확도도 마찬가지로 running_corrects를 데이터셋 사이즈로 나눔\n",
        " \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)) #해당 에포크의 loss와 정확도를 매번 출력\n",
        "\n",
        "            if phase == 'train': #그래프 그리기 위해 train 데이터의 loss와 accuracy 따로 저장\n",
        "                train_losses.append(epoch_loss)\n",
        "                train_accuracy.append(epoch_acc)\n",
        "            if phase == 'val': #그래프 그리기 위해 \bvalidation 데이터의 loss와 accuracy 따로 저장\n",
        "                val_losses.append(epoch_loss)\n",
        "                val_accuracy.append(epoch_acc)\n",
        "          \n",
        "            if phase == 'val' and epoch_acc > best_acc: #validation 모드에서 정확도가 최고 정확도 보다 높으면 업데이트\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) #최고 정확도를 가진 모델을 best_model_wts 변수에 저장\n",
        " \n",
        "        time_elapsed = time.time() - since #한 에포크 돌 때 소요되는 시간 측정(종료 시각 - 시작 시각) \n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) #계산한 시간 분과 초로 출력\n",
        "\n",
        "    #학습 종료 후 \n",
        "    print('Best validation Acc: {:4f}'.format(best_acc)) #validation 중 최고 정확도 출력\n",
        "\n",
        "    #train과 validation의 loss, accuracy 그래프 출력 -> 과적합 여부 등 판단\n",
        "    plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "    plt.legend()\n",
        "    plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'co',label = 'training accuracy')\n",
        "    plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'m',label = 'validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    #정확도가 가장 높았던 모델을 불러와서 반환\n",
        "    model.load_state_dict(best_model_wts) \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "EQ6wBtMAs6pw",
        "outputId": "05bbcf67-f076-4282-8cf6-5fda38a91333"
      },
      "source": [
        "# 전이학습 실행\n",
        "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCH) \n",
        "\n",
        "# 반환 받은 정확도가 가장 높았던 모델을 torch.save 이용해서 저장 (모델 별로 이름 변경해서 저장!)\n",
        "torch.save(model, '/content/drive/MyDrive/plant-leaf-dataset/resnet50.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.3467 Acc: 0.2078\n",
            "val Loss: 2.1117 Acc: 0.4047\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 1.8856 Acc: 0.5714\n",
            "val Loss: 1.6415 Acc: 0.6897\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 1.4680 Acc: 0.7326\n",
            "val Loss: 1.2388 Acc: 0.7677\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 1.1295 Acc: 0.7900\n",
            "val Loss: 0.9438 Acc: 0.8159\n",
            "Completed in 0m 24s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.8586 Acc: 0.8454\n",
            "val Loss: 0.7283 Acc: 0.8603\n",
            "Completed in 0m 24s\n",
            "Best validation Acc: 0.860345\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkyMbUEuMqi"
      },
      "source": [
        "### 7. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwYDjEHtCXm",
        "outputId": "26d7093a-dd4d-49e0-910c-f8afe055c416"
      },
      "source": [
        "# 전이학습 평가 전처리 (위에서 설명한 것과 동일)\n",
        "data_transforms = transforms.Compose([ \n",
        "        transforms.Resize([64,64]),  \n",
        "        transforms.RandomCrop(52),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "\n",
        "#경로 맞춰서 변경해 주세요!\n",
        "test_dataset = ImageFolder(root='/content/drive/MyDrive/plant-leaf-dataset/plant-leaf-new-dataset/test', transform=data_transforms) \n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval() #모델을 평가 모드로 설정\n",
        "    test_loss = 0 #미니 배치 별로 loss를 합산해서 저장\n",
        "    correct = 0 #정확하게 예측한 수 저장   \n",
        "    with torch.no_grad(): #해당 메서드를 이용해서 parameter 업데이트 방지\n",
        "        for data, target in test_loader:  \n",
        "            data, target = data.to(DEVICE), target.to(DEVICE) #데이터와 라벨을 불러오면서 gpu에 태움  \n",
        "            output = model(data) #데이터를 모델에 입력           \n",
        "            test_loss += torch.nn.functional.cross_entropy(output,target, reduction='sum').item() #모델의 예측값과 정답값 사이의 loss 계산\n",
        "            pred = output.max(1, keepdim=True)[1]  #모델에 입력된 데이터가 12개의 클래스에 속할 확률값 출력, 이 중 가장 높은 값의 인덱스를 예측값으로 pred에 저장\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() #target.view_as(pred)를 이용해 target의 텐서 구조를 pred의 텐서와 같은 모양으로 재정렬 (모델 만들 때 쓰는 view와 비슷 view는 숫자 직접 지정)\n",
        "                                                                  #eq는 비교 연산자로 pred와 target.view_as(pred)의 값이 일치하면 1, 일치하지 않으면 0 반환\n",
        "   \n",
        "    test_loss /= len(test_loader.dataset) #모든 미니 배치에서 합한 loss값을 배치 수로 나누어 loss값의 평균 구함\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset) #마찬가지로 정확도의 평균도 구함\n",
        "    \n",
        "    return test_loss, test_accuracy #계산한 Test 데이터의 loss와 정확도 반환\n",
        "\n",
        "# 전이학습 모델 평가 결과\n",
        "model=torch.load('/content/drive/MyDrive/plant-leaf-dataset/resnet50.pt') #torch.load를 이용해서 원하는 모델 불러오기!\n",
        "test_loss, test_accuracy = evaluate(model, test_loader) #평가 함수 이용해서 Test 데이터에 대한 loss 및 정확도 측정\n",
        "print('model test acc:  ', test_accuracy) #평가 정확도 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model test acc:   85.47413793103448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(과제) 한 가지 이상의 변화를 준 후 학습을 돌려서 결과와 함께 간단한 설명을 업로드 해주세요 😀\n",
        "\n",
        "예시 : 다른 전이학습 모델 사용, freeze 시키는 구간 변화, 직접 짠 모델과의 성능 비교, 데이터 수의 변화, optimizer에 대한 실험, epoch 늘리기, 등등"
      ],
      "metadata": {
        "id": "maEk9ITatoai"
      }
    }
  ]
}